{
  "id": "91f6bbe2-ed41-4fd6-bac7-71d5b5864ecb",
  "revision": 0,
  "last_node_id": 87,
  "last_link_id": 147,
  "nodes": [
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        850,
        10
      ],
      "size": [
        300,
        58
      ],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 143
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": []
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        3.1000000000000005
      ]
    },
    {
      "id": 69,
      "type": "MarkdownNote",
      "pos": [
        -540,
        -220
      ],
      "size": [
        390,
        180
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "VRAM Usage",
      "properties": {
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "## GPU:RTX4090D 24GB\n\n| Configuration            | VRAM Usage | 1st Generation | 2nd Generation |\n|---------------------|---------------|---------------|-----------------|\n| Fp8_e4m3fn             | 86%                | â‰ˆ 94s               | â‰ˆ 71s                   |\n| With 8steps LoRA    | 86%                | â‰ˆ 55s               | â‰ˆ 34s                  |\n| Distill fp8_e4m3fn   | 86%                | â‰ˆ 69s               | â‰ˆ 36s                  |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 71,
      "type": "Note",
      "pos": [
        850,
        -120
      ],
      "size": [
        300,
        88
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.5.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Increase the shift if you get too many blury/dark/bad images. Decrease if you want to try increasing detail."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        20,
        50
      ],
      "size": [
        330,
        90
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            129
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "qwen_image_fp8_e4m3fn.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
            "directory": "diffusion_models"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Qwen_Image_fp8_e5m2_scaled_KJ.safetensors",
        "default"
      ]
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        20,
        190
      ],
      "size": [
        330,
        110
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            74,
            75
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "qwen_image",
        "default"
      ]
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        20,
        340
      ],
      "size": [
        330,
        60
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            76
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        390,
        440
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {
        "collapsed": true
      },
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            52
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        ""
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 67,
      "type": "MarkdownNote",
      "pos": [
        -540,
        10
      ],
      "size": [
        536.8095568252323,
        509.56077015252083
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "[Tutorial](https://docs.comfy.org/tutorials/image/qwen/qwen-image) \n\n## Model links\n\nYou can find all the models on [Huggingface](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main) or [Modelscope](https://modelscope.cn/models/Comfy-Org/Qwen-Image_ComfyUI/files)\n\n**Diffusion model**\n\n- [qwen_image_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors)\n\nQwen_image_distill\n\n- [qwen_image_distill_full_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_fp8_e4m3fn.safetensors)\n- [qwen_image_distill_full_bf16.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_bf16.safetensors)\n\n**LoRA**\n\n- [Qwen-Image-Lightning-8steps-V1.0.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors)\n\n**Text encoder**\n\n- [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)\n\n**VAE**\n\n- [qwen_image_vae.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚   â”œâ”€â”€ qwen_image_fp8_e4m3fn.safetensors\nâ”‚   â”‚   â””â”€â”€ qwen_image_distill_full_fp8_e4m3fn.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ loras/\nâ”‚   â”‚   â””â”€â”€ Qwen-Image-Lightning-8steps-V1.0.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ qwen_image_vae.safetensors\nâ”‚   â””â”€â”€ ðŸ“‚ text_encoders/\nâ”‚       â””â”€â”€ qwen_2.5_vl_7b_fp8_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 70,
      "type": "Note",
      "pos": [
        382.3234815942132,
        -139.82996037638443
      ],
      "size": [
        446.0829746907252,
        96.9357457599759
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "For fp8 without 8steps LoRA",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.5.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Set cfg to 1.0 for a speed boost at the cost of consistency. Samplers like res_multistep work pretty well at cfg 1.0\n\nThe official number of steps is 50 but I think that's too much. Even just 10 steps seems to work."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1189.8522933717531,
        -95.83890981522165
      ],
      "size": [
        210,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 128
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            147
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        390,
        240
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 74
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            46
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "A muscular, bald man holds a flower above his head with both arms, set against a soft circular background in black and white."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 58,
      "type": "EmptySD3LatentImage",
      "pos": [
        50,
        510
      ],
      "size": [
        270,
        106
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            107
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "EmptySD3LatentImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        2048,
        3072,
        1
      ]
    },
    {
      "id": 86,
      "type": "VAEDecodeTiled",
      "pos": [
        1198.6859676376419,
        -3.510055414695172
      ],
      "size": [
        214.2893210323973,
        150
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": null
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": []
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.66",
        "Node name for S&R": "VAEDecodeTiled",
        "ue_properties": {
          "widget_ue_connectable": {
            "tile_size": true,
            "overlap": true,
            "temporal_size": true,
            "temporal_overlap": true
          },
          "version": "7.5.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        512,
        64,
        64,
        8
      ]
    },
    {
      "id": 84,
      "type": "Note",
      "pos": [
        127.85552070578971,
        697.2085344493496
      ],
      "size": [
        230.1795530804054,
        88
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "Base resolution for Qwen: 1328 (paper suggests)"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 87,
      "type": "Note",
      "pos": [
        1451.2767236896004,
        -0.28977601296752376
      ],
      "size": [
        230.1795530804054,
        88
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "In case of VAE OOM at higher resolution, use VAE tiled"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 74,
      "type": "MarkdownNote",
      "pos": [
        855.4484793317094,
        646.470925717398
      ],
      "size": [
        291.9524605711331,
        193.0140805375371
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "KSampler settings",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.5.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "You can test and find the best setting by yourself. The following table is for reference.\n\n| model            | steps | cfg |\n|---------------------|---------------|---------------|\n| fp8_e4m3fnï¼ˆQwen team's suggestionï¼‰             | 40                | 2.5               \n| fp8_e4m3fn             | 20                | 2.5               |\n| fp8_e4m3fn + 8steps LoRA    | 8               | 1.0               |\n| distill fp8_e4m3fn   | 10               | 1.0              |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 83,
      "type": "MarkdownNote",
      "pos": [
        -532.5918528644575,
        578.8669399944761
      ],
      "size": [
        527.1046728188984,
        338.93083892915456
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "DyPE",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "### Node Inputs\n\n*   **`method`**: The extrapolation strategy.\n    *   **`vision_yarn`:** Best for 4K+ and non-square images. Fixes stretching and artifacts automatically.\n    *   **`yarn` / `ntk`**: Legacy methods. Use `yarn` with `yarn_alt_scaling` for manual control.\n*   **`enable_dype`**: Toggles the dynamic (time-aware) algorithm. Keep enabled for best quality.\n*   **`dype_scale`**: Magnitude of the frequency shift. Default: `2.0`.\n*   **`dype_exponent`**: Aggressiveness of the dynamic schedule.\n    *   `2.0`: Best for **4K**.\n    *   `1.0`: Best for **2K**.\n    *   `0.5`: Best for **~1.5K**.\n*   **`yarn_alt_scaling`**: *(Legacy `yarn` only)* Switch between Anisotropic (Sharper, potential stretching) and Isotropic (Softer, accurate geometry).\n*   **`base_shift` / `max_shift`**: Advanced noise schedule controls. Defaults (`0.5` / `1.15`) are optimized for FLUX.\n\n\n## Join\n\n### [TokenDiffusion](https://t.me/TokenDiff) - AI for every home, creativity for every mind!\n\n### [TokenDiff Community Hub](https://t.me/TokenDiff_hub) - Questions, help, and thoughtful discussion. "
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 73,
      "type": "LoraLoaderModelOnly",
      "pos": [
        418.83291410517865,
        50.4286704756969
      ],
      "size": [
        347.36824698811677,
        92.36894031799505
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 129
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            142
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-8steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {
            "lora_name": true,
            "strength_model": true
          },
          "version": "7.5.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen\\Qwen-Image-Lightning-8steps-V2.0-bf16.safetensors",
        1
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        850,
        120
      ],
      "size": [
        300,
        474
      ],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 146
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 46
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 52
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 107
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            128
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.5.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        91534580598587,
        "fixed",
        8,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 82,
      "type": "DyPE_FLUX",
      "pos": [
        420.94687820112836,
        578.0070284351821
      ],
      "size": [
        370.4292488218126,
        322
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 142
        }
      ],
      "outputs": [
        {
          "name": "Patched Model",
          "type": "MODEL",
          "links": [
            143,
            146
          ]
        }
      ],
      "properties": {
        "cnr_id": "ComfyUI-DyPE",
        "ver": "a717a8a26882dbb852f19c05d1bfe973d9f7eab3",
        "Node name for S&R": "DyPE_FLUX",
        "ue_properties": {
          "widget_ue_connectable": {
            "width": true,
            "height": true,
            "method": true,
            "enable_dype": true,
            "dype_exponent": true,
            "base_shift": true,
            "max_shift": true
          },
          "version": "7.5.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        4096,
        4096,
        "auto",
        "vision_yarn",
        true,
        true,
        1328,
        1,
        2,
        10,
        0.5,
        1.15
      ],
      "color": "#332922",
      "bgcolor": "#593930"
    },
    {
      "id": 85,
      "type": "SaveImage",
      "pos": [
        1190.7567281085715,
        197.79219937488617
      ],
      "size": [
        507.8598899428216,
        713.1719633545902
      ],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 147
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "qwen_dype"
      ]
    }
  ],
  "links": [
    [
      46,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      52,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      74,
      38,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      75,
      38,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      76,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      107,
      58,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      128,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      129,
      37,
      0,
      73,
      0,
      "MODEL"
    ],
    [
      142,
      73,
      0,
      82,
      0,
      "MODEL"
    ],
    [
      143,
      82,
      0,
      66,
      0,
      "MODEL"
    ],
    [
      146,
      82,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      147,
      8,
      0,
      85,
      0,
      "IMAGE"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step1 - Load models",
      "bounding": [
        10,
        -20,
        350,
        433.6000061035156
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step2 - Image size",
      "bounding": [
        10,
        430,
        350,
        210
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [
        380,
        160,
        455.6520647011346,
        296.19901044011226
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Lightx2v 8steps LoRA",
      "bounding": [
        380,
        -20,
        450,
        170
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 6,
      "title": "Model Patching",
      "bounding": [
        384.83801869752796,
        481.45994817875567,
        449.90889198206656,
        448.6671733031452
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7077059820630021,
      "offset": [
        755.6494571265252,
        282.90090632629403
      ]
    },
    "frontendVersion": "1.32.9",
    "ue_links": [],
    "links_added_by_ue": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true,
    "workflowRendererVersion": "LG"
  },
  "version": 0.4
}